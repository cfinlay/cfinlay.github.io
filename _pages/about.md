---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a post-doctoral researcher at [McGill University](https://www.mcgill.ca/) in machine learning, and a visiting research fellow at the [Institute for Pure and Applied Mathematics](https://www.ipam.ucla.edu/) at UCLA. My PhD was in applied math, where I was supervised by 
[Adam Oberman](https://www.adamoberman.net/).  My research interests lie at the intersection of artificial intelligence, machine learning, and applied math. I'm a numerical analyst
by training, which means I love creating and dissecting algorithms for use in
scientific computing, and studying their convergence and stability properties.

My current research interests include robust optimization for deep neural networks, unsupervised learning (density estimation and generative models), and neural ODEs. I am also actively studying connections between Variational Calculus, neural ODEs and optimal control.

Before jumping on the machine learning bandwagon, I studied algorithms for solving nonlinear
elliptic Partial Differential Equations (PDEs). These are equations that
describe "diffusion-like" behaviour, in that they have properties very similar
to the Laplace operator. These types of equations are very common and describe
a wide range of physical phenomenon in physics and engineering, including optimal control (through the HJB operator) and inverse problems. 

Prior to grad school, I worked as a data analyst for [Natural Resources
Canada](https://www.nrcan.gc.ca/home).
