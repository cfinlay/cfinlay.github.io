---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a PhD candidate in applied mathematics at [McGill University](https://www.mcgill.ca/), working with
[Adam Oberman](https://www.adamoberman.net/).  My research interests lie at the intersection of artificial intelligence, machine learning, and applied math. I'm a numerical analyst
by training, which means I love creating and dissecting algorithms for use in
scientific computing, and studying their convergence and stability properties.

I am currently working on robust optimization for neural networks in machine learning. Robust optimization focuses on finding neural networks that perform well *and* are stable (robust) to perturbations. Unfortunately, by default neural networks don't seem to be stable at all. For example in computer vision, neural networks can achieve impressive performance classifying natural images, yet can be easily fooled by tiny changes to only a few pixels. These changes are known as [adversarial examples](https://medium.com/@ml.at.berkeley/tricking-neural-networks-create-your-own-adversarial-examples-a61eb7620fd8) and there is a vast and very active body of research on the topic. 
Needless to say, addressing this glaring security vulnerability is one of the foremost challenges in deep learning today.

Before joining the zeitgeist, I studied algorithms for solving nonlinear
elliptic Partial Differential Equations (PDEs). These are equations that
describe "diffusion-like" behaviour, in that they have properties very similar
to the Laplace operator. These types of equations are very common and describe
a wide range of physical phenomenon in physics and engineering, including optimal control (through the HJB operator) and inverse problems. 

Prior to grad school, I worked as a data analyst for [Natural Resources
Canada](https://www.nrcan.gc.ca/home); in ancient times I was a guitar
instructor and underemployed musician.
